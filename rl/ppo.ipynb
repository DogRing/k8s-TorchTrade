{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_encoding(dt_index,weights=None):\n",
    "    weights = weights or { 'hour':0.1,'day':0.4,'week':0.3,'year':0.2 }\n",
    "    timestamps = dt_index.view('int64') // 10**9\n",
    "    hour_angle = (timestamps%3600) / 3600 * 2 * np.pi\n",
    "    day_angle = (timestamps%86400) / 86400 * 2 * np.pi\n",
    "    week_angle = (timestamps%604800) / 603800 * 2 * np.pi\n",
    "    year_seconds = 365.25 * 86400\n",
    "    year_angle = (timestamps % year_seconds)/year_seconds*2*np.pi\n",
    "    sin_sum = (\n",
    "        weights['hour']*np.sin(hour_angle)+\n",
    "        weights['day']*np.sin(day_angle)+\n",
    "        weights['week']*np.sin(week_angle)+\n",
    "        weights['year']*np.sin(year_angle)\n",
    "    )\n",
    "    cos_sum = (\n",
    "        weights['hour']*np.cos(hour_angle)+\n",
    "        weights['day']*np.cos(day_angle)+\n",
    "        weights['week']*np.cos(week_angle)+\n",
    "        weights['year']*np.cos(year_angle)\n",
    "    )\n",
    "    final_angle = (np.arctan2(sin_sum,cos_sum)+np.pi)/(2*np.pi)\n",
    "    return pd.Series(final_angle,index=dt_index,name='time')\n",
    "\n",
    "class MultiTimeDataset(Dataset):\n",
    "    def __init__(self,path,tick,input_dims,batch_size=64,device='cpu'):\n",
    "        super(MultiTimeDataset,self).__init__()\n",
    "        self.timeframes = input_dims.keys()\n",
    "        file_name = f'{path}{tick}.csv'\n",
    "        df=pd.read_csv(file_name,parse_dates=[0],index_col=[0])\n",
    "        self.x = {k:torch.tensor(\n",
    "            df[[col for col in df.columns if col.startswith(k)]].values,\n",
    "            device=device, dtype=torch.float32\n",
    "        ) for k in self.timeframes}\n",
    "        non_tf_cols = [col for col in df.columns\n",
    "                        if not any(col.startswith(prefix) for prefix in self.timeframes)\n",
    "                        and col != 'close']\n",
    "        self.x['1'] = torch.tensor(\n",
    "            df[non_tf_cols].values,\n",
    "            device=device, dtype=torch.float32\n",
    "        )\n",
    "        self.times = torch.tensor(\n",
    "            angle_encoding(df.index).values,\n",
    "            device=device, dtype=torch.float32\n",
    "        )\n",
    "        time_indices = {\n",
    "            k:np.arange(-int(k)*(v-1),int(k),int(k)) \n",
    "            for k,v in input_dims.items() \n",
    "        }\n",
    "        om = min(arr.min() for arr in time_indices.values())\n",
    "        non_nan_index = df.index.get_loc(df.index[~df.isna().any(axis=1)][0])\n",
    "        self.indices = {\n",
    "            k:arr + abs(om) + non_nan_index\n",
    "            for k,arr in time_indices.items()\n",
    "        }\n",
    "        self.len = len(df)-(abs(om)+non_nan_index)\n",
    "        y = df.close.iloc[non_nan_index+abs(om):]\n",
    "        self.y = (y - y.mean()) / (y.std(ddof=0) + 1e-8)\n",
    "        self.y = torch.tensor(self.y.values)\n",
    "        self._precompute_first_batch_indices(batch_size)\n",
    "        \n",
    "    def _precompute_first_batch_indices(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        total_samples = len(self)\n",
    "        self.num_batches = (total_samples+ self.batch_size - 1) // self.batch_size\n",
    "        self.first_batch_indices = {}\n",
    "        first_batch_size = min(self.batch_size,total_samples)\n",
    "        for tf in self.timeframes:\n",
    "            indices_matrix = self.indices[tf] + np.arange(first_batch_size,dtype=np.int32)[:,np.newaxis]\n",
    "            self.first_batch_indices[tf] = indices_matrix\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {\n",
    "            tf: (\n",
    "                self.x[tf][self.indices[tf]+idx],\n",
    "                self.times[self.indices[tf]+idx]\n",
    "            )\n",
    "            for tf in self.timeframes\n",
    "        },self.y[idx]\n",
    "    \n",
    "    def _get_batch_indices(self,batch_idx):\n",
    "        start_idx = batch_idx * self.batch_size\n",
    "        end_idx = min(start_idx + self.batch_size, len(self))\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def _prepare_batch(self, batch_idx):\n",
    "        if batch_idx >= self.num_batches:\n",
    "            raise IndexError(\"Batch index out of range\")\n",
    "        start_idx,end_idx = self._get_batch_indices(batch_idx)\n",
    "        current_batch_size = end_idx - start_idx\n",
    "        batch_data = {}\n",
    "        for tf in self.timeframes:\n",
    "            base_indices = self.first_batch_indices[tf][:current_batch_size]\n",
    "            adjusted_indices = base_indices + start_idx\n",
    "            x_batch = self.x[tf][adjusted_indices]\n",
    "            times_batch = self.times[adjusted_indices]\n",
    "            batch_data[tf] = (x_batch,times_batch)\n",
    "        batch_labels = self.y[start_idx:end_idx]\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "    def iter_batch(self):\n",
    "        for batch_idx in range(self.num_batches):\n",
    "            yield self._prepare_batch_fast(batch_idx)\n",
    "            \n",
    "    def get_batch(self,batch_idx):\n",
    "        return self._prepare_batch(batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierTimeEmbedding(nn.Module):\n",
    "    \"\"\" 시간 정보를 푸리에 변환을 사용하여 임베딩하는 모듈\n",
    "    시간 정보를 주기적인 특성을 가진 고차원 벡터로 변환합니다.\n",
    "    \n",
    "    input: \n",
    "        - t: Tensor of shape [batch_size, sequence_length, 1]\n",
    "    output: \n",
    "        - Shape: [batch_size, sequence_length, embed_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self,embed_dim=32,num_bands=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(2*num_bands,embed_dim)\n",
    "        coeffs = torch.linspace(0, 1, num_bands)\n",
    "        self.register_buffer('coeffs', coeffs * 2.0 * torch.pi)\n",
    "    def forward(self,t):\n",
    "        embed = torch.einsum('bs,n->bsn', t, self.coeffs)\n",
    "        embed = torch.cat([torch.sin(embed),torch.cos(embed)],dim=-1)\n",
    "        return self.fc(embed)\n",
    "\n",
    "class ExecutionHyridModule(nn.Module):\n",
    "    \"\"\" 1분봉 데이터를 처리하는 CNN-GRU 하이브리드 모듈\n",
    "    CNN으로 지역적 특징을 추출하고 GRU로 시계열 정보를 처리합니다.\n",
    "    \n",
    "    input:\n",
    "        - x: Input features [batch_size, sequence_length, feature_dim]\n",
    "        - t: Time information [batch_size, sequence_length]\n",
    "    output:\n",
    "        - Shape: [batch_size, sequence_length, proj_size]\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_dim,time_dim=32,hidden_size=32,proj_size=64):\n",
    "        super().__init__()\n",
    "        self.time_embed = FourierTimeEmbedding(time_dim)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim+time_dim,hidden_size,5,padding=2),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(hidden_size)\n",
    "        )\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size,batch_first=True)\n",
    "        self.proj = nn.Linear(hidden_size, proj_size)\n",
    "    def forward(self,x,t):\n",
    "        t_emb = self.time_embed(t)\n",
    "        x = torch.cat([x,t_emb],dim=-1).permute(0,2,1)\n",
    "        conv_out = self.conv(x).permute(0,2,1)\n",
    "        gru_out,_ = self.gru(conv_out)\n",
    "        return self.proj(gru_out)\n",
    "\n",
    "class MultiScaleLSTM(nn.Module):\n",
    "    \"\"\" 15분/4시간 봉 데이터를 위한 멀티스케일 LSTM 모듈\n",
    "    여러 시간 스케일에서 LSTM을 적용하여 다양한 시간대의 패턴을 포착합니다.\n",
    "    \n",
    "    input:\n",
    "        - x: Input features [batch_size, sequence_length, feature_dim]\n",
    "        - t: Time information [batch_size, sequence_length]\n",
    "    outpu:\n",
    "        - Shape: [batch_size, sequence_length, proj_size]\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_dim,time_dim=32,scales=[5,10,20],hidden_size=32,proj_size=64):\n",
    "        super().__init__()\n",
    "        self.time_embed = FourierTimeEmbedding(time_dim)\n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=feature_dim+time_dim,\n",
    "                hidden_size=hidden_size,\n",
    "                batch_first=True)\n",
    "            for _ in scales\n",
    "        ])\n",
    "        self.attn = nn.MultiheadAttention(hidden_size*len(scales),4,batch_first=True)\n",
    "        self.proj = nn.Linear(hidden_size*len(scales),proj_size)\n",
    "    def forward(self,x,t):\n",
    "        t_emb = self.time_embed(t)\n",
    "        x_in = torch.cat([x,t_emb],dim=-1)\n",
    "        outputs = []\n",
    "        for lstm in self.lstms:\n",
    "            out,_ = lstm(x_in)\n",
    "            outputs.append(out)\n",
    "        concat = torch.cat(outputs,dim=-1)\n",
    "        attn_out,_ = self.attn(concat,concat,concat)\n",
    "        return self.proj(attn_out)\n",
    "\n",
    "class HierarchicalTransformer(nn.Module):\n",
    "    \"\"\" 1시간/일 봉 데이터를 처리하는 트랜스포머 기반 모듈\n",
    "    자기 주의 메커니즘을 통해 장기 의존성을 포착합니다.\n",
    "    \n",
    "    input: \n",
    "        - x: Input features [batch_size, sequence_length, feature_dim]\n",
    "        - t: Time information [batch_size, sequence_length]\n",
    "    output:\n",
    "        - Shape: [batch_size, sequence_length, proj_size]\n",
    "        - Calculation: TransformerEncoder(Linear(concat[x, TimeEmbed(t)]), layers=2)\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_dim,time_dim=32,nhead=4,proj_size=64,num_layers=2):\n",
    "        super().__init__()\n",
    "        self.time_embed = FourierTimeEmbedding(time_dim)\n",
    "        self.input_proj = nn.Linear(feature_dim+time_dim,proj_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=proj_size,nhead=nhead,dim_feedforward=256,\n",
    "            activation='gelu',batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer,num_layers)\n",
    "    def forward(self,x,t):\n",
    "        t_emb = self.time_embed(t)\n",
    "        x_in = torch.cat([x,t_emb],dim=-1)\n",
    "        projected = self.input_proj(x_in)\n",
    "        return self.encoder(projected)\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    \"\"\" 다중 시간대 특징을 통합하는 교차 모달 어텐션 모듈\n",
    "    서로 다른 시간대의 특징들 간의 관계를 학습합니다.\n",
    "    \n",
    "    input: \n",
    "        - features: List of tensors [batch_size, time_steps, input_dim_i] for each timeframe\n",
    "    output:\n",
    "        - Shape: [batch_size, time_steps, num_timeframes × embed_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dims, embed_dim=32, heads=4):\n",
    "        super().__init__()\n",
    "        self.timeframes = input_dims.keys()\n",
    "        num_timeframes = len(self.timeframes)\n",
    "        self.projections = nn.ModuleList([\n",
    "            nn.Linear(dim,embed_dim)\n",
    "            for tf, dim in input_dims.items()\n",
    "        ])\n",
    "        self.attentions = nn.ModuleList([\n",
    "            nn.MultiheadAttention(embed_dim, heads, batch_first=True)\n",
    "            for _ in range(num_timeframes)\n",
    "        ])\n",
    "        self.norms = nn.ModuleList([\n",
    "            nn.LayerNorm(embed_dim)\n",
    "            for _ in range(num_timeframes)\n",
    "        ])\n",
    "        self.timeframe_weights = nn.Parameter(torch.ones(num_timeframes)/num_timeframes)\n",
    "        self.final_norm = nn.LayerNorm(embed_dim * num_timeframes)\n",
    "    def forward(self, features):\n",
    "        features = [proj(feat.transpose(1,2)).transpose(1,2)\n",
    "            for proj,feat in zip(self.projections,features)]\n",
    "        context = torch.stack(features, dim=1)\n",
    "        B, K, T, D = context.shape\n",
    "        context = context.view(B*T, K, D)\n",
    "        attn_outs = []\n",
    "        for i, (attn, norm) in enumerate(zip(self.attentions, self.norms)):\n",
    "            query = context[:, i:i+1]\n",
    "            out, _ = attn(query, context, context)\n",
    "            attn_outs.append(norm(out + query))\n",
    "        weights = F.softmax(self.timeframe_weights,dim=0)\n",
    "        combined = torch.stack(attn_outs,dim=1)*weights.view(1,K,1,1)\n",
    "        fused = combined.view(B,T,K*D)\n",
    "        return self.final_norm(fused)\n",
    "\n",
    "class EnhancedMultiTimeframeModel(nn.Module):\n",
    "    \"\"\" 다중 시간대 데이터를 처리하는 강화학습 모델\n",
    "    각 시간대별로 특화된 모듈을 사용하여 특징을 추출하고,\n",
    "    이를 통합하여 행동(actor)과 가치(critic) 예측을 수행합니다.\n",
    "    \n",
    "    input:\n",
    "        - inputs: Dictionary mapping timeframe to (data, time) pairs\n",
    "          - data: [batch_size, time_steps, feature_dims[timeframe]]\n",
    "          - time: [batch_size, time_steps, 1]\n",
    "        - feature_dims: Dictionary of input dimensions per timeframe\n",
    "        - action_dim: Number of possible actions (default=3 for long/neutral/short)\n",
    "    output:\n",
    "        - dist: Categorical distribution [batch_size, time_steps, action_dim]\n",
    "        - value: [batch_size, time_steps, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dims, input_dims, action_dim):\n",
    "        super().__init__()\n",
    "        self.timeframes = list(feature_dims.keys())\n",
    "        time_dim = 16\n",
    "        hidden_size = 128\n",
    "        proj_size = 64\n",
    "        \n",
    "        self.modules_dict = nn.ModuleDict()\n",
    "        for tf, dim in feature_dims.items():\n",
    "            if int(tf) <= 20:\n",
    "                self.modules_dict[tf] = ExecutionHyridModule(dim,\n",
    "                    time_dim=time_dim,hidden_size=hidden_size,proj_size=proj_size\n",
    "                )\n",
    "            elif int(tf) <= 100:\n",
    "                self.modules_dict[tf] = MultiScaleLSTM(dim,\n",
    "                    time_dim=time_dim,hidden_size=hidden_size,proj_size=proj_size\n",
    "                )\n",
    "            else:\n",
    "                self.modules_dict[tf] = HierarchicalTransformer(dim,\n",
    "                    time_dim=time_dim,proj_size=proj_size\n",
    "                )\n",
    "        \n",
    "        self.fusion = CrossModalAttention(input_dims,embed_dim=64)\n",
    "        fusion_dim = 64 * len(self.timeframes)\n",
    "    \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "        \n",
    "        # Critic 네트워크 (가치 예측)\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        features = []\n",
    "        # 입력된 모든 시간대에 대해 처리\n",
    "        for tf in self.timeframes:\n",
    "            data, time = inputs[tf]\n",
    "            out = self.modules_dict[tf](data, time)\n",
    "            features.append(out)\n",
    "        # 특징 융합\n",
    "        fused = self.fusion(features)\n",
    "        logits = self.actor(fused)\n",
    "        dist = Categorical(logits=logits)\n",
    "        value = self.critic(fused)\n",
    "        return dist, value\n",
    "    def get_action(self,inputs,deterministic=False,mode='last'):\n",
    "        dist,value = self.forward(inputs)\n",
    "        if deterministic:\n",
    "            action = torch.argmax(dist.probs,dim=-1)\n",
    "        else:\n",
    "            action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        if mode == 'last':\n",
    "            return action[:,-1],log_prob[:,-1],entropy[:,-1],value[:,-1]\n",
    "        elif mode == 'mean':\n",
    "            return action[:,-1],log_prob.mean(dim=1),entropy.mean(dim=1),value.mean(dim=1,keepdim=True)\n",
    "        else:\n",
    "            return action,log_prob,entropy,value\n",
    "    \n",
    "    def get_logprob(self,inputs,action,mode='last'):\n",
    "        dist,value = self.forward(inputs)\n",
    "        B,T,_ = dist.probs.shape\n",
    "        action = action.unsqueeze(1).expand(B, T)\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        if mode == 'last':\n",
    "            return log_prob[:, -1], entropy[:, -1], value[:, -1]\n",
    "        elif mode == 'mean':\n",
    "            return log_prob.mean(dim=1), entropy.mean(dim=1), value.mean(dim=1, keepdim=True)\n",
    "        else:\n",
    "            return log_prob,entropy,value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "CLIP_EPSILON = 0.2\n",
    "CRITIC_DISCOUNT = 0.5\n",
    "ENTROPY_BETA = 0.01\n",
    "LEARNING_RATE = 3e-4\n",
    "PPO_EPOCHS = 10\n",
    "MINI_BATCH_SIZE = 64\n",
    "MAX_GRAD_NORM = 0.5\n",
    "\n",
    "class PPOMemory:\n",
    "    def __init__(self):\n",
    "        self.states_index = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.values = []\n",
    "        self.log_probs = []\n",
    "        self.dones = []\n",
    "    def push(self,state_index,action,reward,value,log_prob,done):\n",
    "        self.states_index.append(state_index)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.values.append(value)\n",
    "        self.log_probs.append(log_prob)\n",
    "        self.dones.append(done)\n",
    "    def get(self):\n",
    "        return (\n",
    "            self.states_index,\n",
    "            torch.stack(self.actions),\n",
    "            torch.stack(self.rewards),\n",
    "            torch.stack(self.values),\n",
    "            torch.stack(self.log_probs),\n",
    "            torch.tensor(self.dones,device=self.actions[0].device)\n",
    "        )\n",
    "    def clear(self):\n",
    "        self.states_index.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "        self.values.clear()\n",
    "        self.log_probs.clear()\n",
    "        self.dones.clear()\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, feature_dims, input_dims, n_actions, device):\n",
    "        self.policy = EnhancedMultiTimeframeModel(feature_dims, input_dims, n_actions).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=LEARNING_RATE)\n",
    "        self.memory = PPOMemory()\n",
    "        self.mode = \"last\"\n",
    "        self.device = device\n",
    "        self.scaler = torch.amp.GradScaler()\n",
    "    def compute_gae(self, next_value, rewards, values, dones):\n",
    "        values = torch.cat([values, next_value.T]).to(torch.float32)\n",
    "        gae = 0\n",
    "        returns = torch.zeros_like(rewards,device=self.device,dtype=torch.float32)\n",
    "        advantages = torch.zeros_like(rewards,device=self.device,dtype=torch.float32)\n",
    "        for steps in reversed(range(len(rewards))):\n",
    "            delta = rewards[steps] + GAMMA * values[steps + 1] * (1 - dones[steps]) - values[steps]\n",
    "            gae = delta + GAMMA * GAE_LAMBDA * (1 - dones[steps]) * gae\n",
    "            advantages[steps] = gae\n",
    "            rewards[steps] = gae + values[steps]\n",
    "        return returns, advantages\n",
    "    def update(self,next_value,dataset):\n",
    "        device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'\n",
    "        states_indexs, actions, rewards, values, old_log_probs, dones = self.memory.get()\n",
    "        returns, advantages = self.compute_gae(next_value,rewards,values,dones)\n",
    "        returns = returns.detach()\n",
    "        advantages = advantages.detach()\n",
    "        old_log_probs = [log_prob.detach() for log_prob in old_log_probs]\n",
    "        returns = returns.view(-1,MINI_BATCH_SIZE)\n",
    "        advantages = advantages.view(-1,MINI_BATCH_SIZE)\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "        for _ in range(PPO_EPOCHS):\n",
    "            for batch_idx in states_indexs:\n",
    "                with torch.amp.autocast(device_type=device_type,dtype=torch.float32):\n",
    "                    mb_states,_ = dataset.get_batch(batch_idx)\n",
    "                    mb_actions = actions[batch_idx]\n",
    "                    mb_returns = returns[batch_idx].view(-1)\n",
    "                    mb_advantages = advantages[batch_idx]\n",
    "                    mb_old_log_prob = old_log_probs[batch_idx]\n",
    "                    \n",
    "                    new_log_prob,entropy,values = self.policy.get_logprob(mb_states, mb_actions, self.mode)\n",
    "                    ratio = torch.exp(new_log_prob - mb_old_log_prob)\n",
    "                    surr1 = ratio * mb_advantages\n",
    "                    surr2 = torch.clamp(ratio, 1.0 - CLIP_EPSILON, 1.0 + CLIP_EPSILON) * mb_advantages\n",
    "                    actor_loss = -torch.min(surr1,surr2).mean()\n",
    "                    critic_loss = F.mse_loss(values.squeeze(-1), mb_returns, reduction='mean')\n",
    "                    loss = actor_loss + CRITIC_DISCOUNT * critic_loss - ENTROPY_BETA * entropy.mean()\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                nn.utils.clip_grad_norm_(self.policy.parameters(),MAX_GRAD_NORM)\n",
    "\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "\n",
    "        self.memory.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\changh\\AppData\\Local\\Temp\\ipykernel_19752\\2929410975.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.current_price = labels[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (64, 64, 3)) of distribution Categorical(logits: torch.Size([64, 64, 3])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        ...,\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]]], device='cuda:0', grad_fn=<SubBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         _,_,_,next_value = agent.policy.get_action(state, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mPPOAgent.update\u001b[39m\u001b[34m(self, next_value, dataset)\u001b[39m\n\u001b[32m     81\u001b[39m mb_advantages = advantages[batch_idx]\n\u001b[32m     82\u001b[39m mb_old_log_prob = old_log_probs[batch_idx]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m new_log_prob,entropy,values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_logprob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmb_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmb_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m ratio = torch.exp(new_log_prob - mb_old_log_prob)\n\u001b[32m     88\u001b[39m surr1 = ratio * mb_advantages\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 233\u001b[39m, in \u001b[36mEnhancedMultiTimeframeModel.get_logprob\u001b[39m\u001b[34m(self, inputs, action, mode)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_logprob\u001b[39m(\u001b[38;5;28mself\u001b[39m,inputs,action,mode=\u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     dist,value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m     B,T,_ = dist.probs.shape\n\u001b[32m    235\u001b[39m     action = action.unsqueeze(\u001b[32m1\u001b[39m).expand(B, T)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 214\u001b[39m, in \u001b[36mEnhancedMultiTimeframeModel.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    212\u001b[39m fused = \u001b[38;5;28mself\u001b[39m.fusion(features)\n\u001b[32m    213\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.actor(fused)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m dist = \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m value = \u001b[38;5;28mself\u001b[39m.critic(fused)\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dist, value\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\repos\\ttrade\\.conda\\Lib\\site-packages\\torch\\distributions\\categorical.py:72\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, probs, logits, validate_args)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m._num_events = \u001b[38;5;28mself\u001b[39m._param.size()[-\u001b[32m1\u001b[39m]\n\u001b[32m     69\u001b[39m batch_shape = (\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m._param.size()[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param.ndimension() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch.Size()\n\u001b[32m     71\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\repos\\ttrade\\.conda\\Lib\\site-packages\\torch\\distributions\\distribution.py:71\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     69\u001b[39m         valid = constraint.check(value)\n\u001b[32m     70\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid.all():\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     72\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m             )\n\u001b[32m     78\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: Expected parameter logits (Tensor of shape (64, 64, 3)) of distribution Categorical(logits: torch.Size([64, 64, 3])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        ...,\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]],\n\n        [[nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan],\n         ...,\n         [nan, nan, nan],\n         [nan, nan, nan],\n         [nan, nan, nan]]], device='cuda:0', grad_fn=<SubBackward0>)"
     ]
    }
   ],
   "source": [
    "class TradingEnv:\n",
    "    def __init__(self,path,ticks,input_dims,batch_size,max_step,device='cpu'):\n",
    "        self.max_step = max_step\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = torch.arange(batch_size, device=device)\n",
    "        self.datasets = [MultiTimeDataset(path,tick,input_dims,batch_size,device) for tick in ticks]\n",
    "        self.reset(0)\n",
    "    def reset(self,batch_index):\n",
    "        self.dataset = self.datasets[random.randint(0,len(self.datasets)-1)]\n",
    "        self.position = False\n",
    "        self.current_price = None\n",
    "        self.transaction_cost = 0.0005\n",
    "        self.n_step = 0\n",
    "        self.total_reward = 1\n",
    "        self.last_reward = 0\n",
    "        return self.dataset.get_batch(batch_index)\n",
    "    def step(self,actions,labels,batch_index):\n",
    "        if not self.current_price:\n",
    "            self.current_price = labels[0]\n",
    "        actions[0] = 1 if actions[0] == position + 1 else actions[0]\n",
    "\n",
    "        mask = actions != 1\n",
    "\n",
    "        if mask.any():\n",
    "            non_zero_idxs = self.indices[mask]\n",
    "            if len(non_zero_idxs) > 1:\n",
    "                diff = torch.diff(actions[mask])\n",
    "                change_mask = diff != 0\n",
    "                if change_mask.any():\n",
    "                    changes = torch.nonzero(change_mask).squeeze(-1)\n",
    "                    final_idxs = torch.cat([non_zero_idxs[[0]], non_zero_idxs[changes + 1]])\n",
    "                else:\n",
    "                    final_idxs = non_zero_idxs[[0]]\n",
    "            else:\n",
    "                final_idxs = non_zero_idxs\n",
    "        else:\n",
    "            final_idxs = torch.tensor([], device=self.device, dtype=torch.long)\n",
    "\n",
    "        current_prices = torch.zeros_like(labels,device=self.device)\n",
    "        current_prices[final_idxs] = labels[final_idxs]\n",
    "\n",
    "        cum_max_indices = torch.cummax(\n",
    "            torch.where(current_prices != 0,\n",
    "                        self.indices, torch.tensor(-1, device=self.device)\n",
    "            ), dim=0)[0]\n",
    "        current_prices = torch.where(cum_max_indices >= 0, current_prices[cum_max_indices], self.current_price)\n",
    "        current_price = current_prices[-1]\n",
    "        current_prices = torch.roll(current_prices, shifts=1)\n",
    "        current_prices[0] = current_prices[1]\n",
    "\n",
    "        positions = self.position * (-1) ** (self.indices.unsqueeze(1) > final_idxs.unsqueeze(0)).sum(dim=1)\n",
    "        self.position = positions[-1] if final_idxs == n else positions[-1]*-1\n",
    "\n",
    "        profit = (labels - current_prices) / labels * positions\n",
    "        profit[final_idxs] = torch.where(positions[final_idxs] == -1, profit[final_idxs] - self.transaction_cost, profit[final_idxs])\n",
    "\n",
    "        rewards = torch.where(torch.isin(self.indices,final_idxs),profit,profit*0.01)\n",
    "        \n",
    "        self.n_step += 1\n",
    "        self.total_reward *= torch.prod(rewards + 1).item()\n",
    "        if (self.total_reward < 0.9) or (self.n_step >= self.max_step):\n",
    "            done = 1\n",
    "        rewards[0] += self.last_reward\n",
    "        rewards = torch.cumsum(rewards,dim=0)\n",
    "        self.last_reward = rewards[-1].item()\n",
    "        states, labels = self.dataset.get_batch(batch_index)\n",
    "        return states, labels, rewards, done\n",
    "\n",
    "path = \"./250304/\"\n",
    "ticks = [\"KRW-BTC\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "feature_dims = {\n",
    "    '1': 4, '15':6, '60':3, '240':6, '1440':8\n",
    "}\n",
    "\n",
    "input_dims = {\n",
    "    '1':140,'15':15,'60':15,'240':15,'1440':10\n",
    "}\n",
    "\n",
    "max_steps = 48\n",
    "env = TradingEnv(path,ticks,input_dims,feature_dims,MINI_BATCH_SIZE,max_steps,device)\n",
    "agent = PPOAgent(feature_dims, input_dims, 3, device)\n",
    "\n",
    "num_episodes = 10\n",
    "update_interval = 16\n",
    "for episode in range(num_episodes):\n",
    "    batch_index = 0\n",
    "    state, label = env.reset(batch_index)\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for step in range(batch_index, batch_index+max_steps):\n",
    "        with torch.no_grad():\n",
    "            action,log_prob,_,value = agent.policy.get_action(state,deterministic=(random.random() < 0.5))\n",
    "        next_batch_index = batch_index + 1\n",
    "        next_state,next_label,reward,done = env.step(action,label,next_batch_index)\n",
    "        agent.memory.push(batch_index, action, reward, log_prob, value, done)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        \n",
    "        if (step + 1) % update_interval == 0 or done:\n",
    "            with torch.amp.autocast(device_type=device.type):\n",
    "                _,_,_,next_value = agent.policy.get_action(\n",
    "                    state, deterministic=True) if not done else (\n",
    "                    None,None,None,torch.zeros_like(value)\n",
    "                )\n",
    "            agent.update(next_value, env.dataset)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Episode: {episode+1}, Reward: {episode_reward.float().mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
